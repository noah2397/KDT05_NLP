{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"PP.py\"))))\n",
    "\n",
    "from PP import NLP_PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 기반 토크나이저 : Soynlp\n",
    "# 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저\n",
    "# 비지도 학습으로 단어 토큰화 : 데이터에 자주 등장하는 단어들을 단어로 분석\n",
    "# 내부적으로 단어 점수 표로 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soynlp\n",
    "# https://github.com/lovit/soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n",
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정', '이다']\n",
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt()\n",
    "\n",
    "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))\n",
    "\n",
    "## 형태소 분석 시 매개변수 stem=True 설정\n",
    "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정 입니다', stem=True))\n",
    "\n",
    "print(tokenizer.morphs(\"에이비식스 이대휘 1월 최애돌 기부 요정\", norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Sonlpy]사용 => 말뭉치 데이터셋으로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "filename = \"text_data.txt\"\n",
    "\n",
    "if not os.path.exists(path=filename):\n",
    "    urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 데이터 처리\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 문서 : 30091개\n"
     ]
    }
   ],
   "source": [
    "## 훈련 데이터 문서 분리\n",
    "corpus = DoublespaceLineCorpus(filename)\n",
    "print(f\"훈련 데이터 문서 : {len(corpus)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.823 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "### Sonlpy 학습 진행\n",
    "word_extractor = WordExtractor()\n",
    "# 학습 진행하여 단어별 점수\n",
    "word_extractor.train(corpus)\n",
    "# 단어별 점수표 추출\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] - 될\n",
      "[1] - 싶\n",
      "[2] - 뻘\n",
      "[3] - 5\n",
      "[4] - 뉴\n",
      "[5] - 역\n",
      "[6] - 봐\n",
      "[7] - 궐\n",
      "[8] - 균\n",
      "[9] - 낱\n",
      "[10] - 랍\n",
      "[11] - 찔\n",
      "[12] - 콩\n",
      "[13] - 7\n",
      "[14] - 팰\n",
      "[15] - 윽\n",
      "[16] - 능\n",
      "[17] - 컷\n",
      "[18] - 톈\n",
      "[19] - 클\n",
      "[20] - 뱀\n",
      "[21] - 쐈\n",
      "[22] - 빕\n",
      "[23] - 향\n",
      "[24] - 핏\n",
      "[25] - 접\n",
      "[26] - ㅇ\n",
      "[27] - 끓\n",
      "[28] - 누\n",
      "[29] - 그\n",
      "[30] - 절\n"
     ]
    }
   ],
   "source": [
    "# 단어별 점수표 확인\n",
    "for idx, key in enumerate(iterable = word_score_table.keys()):\n",
    "    print(f'[{idx}] - {key}')\n",
    "    if idx==30: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응집확률(cohesion probability) : 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도\n",
    "\n",
    "#    - 원리 : 문자열을 문자 단위로 분리, 왼쪽부터 순서대로 문자를 추가\n",
    "#             각 문자열이 주어졌을 때 그 다음 문자가 나올 확률을 계산/ 누적곱 한 값\n",
    "\n",
    "#    - 값이 높을수록 : 전체 코퍼스에서 이 문자열 시퀸스는 하나의 단어로 등장할 가능성 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06393648140409527"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table['바다'].cohesion_forward # 일반 명사만 나올 확률을 낮다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11518621707955429"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table['바다에'].cohesion_forward # \"바다에\"처럼 명사 + 조사가 나올 확률을 상대적으로 높다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table['바'].cohesion_forward # 얘만 나올 확률은 0이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOYNLP의 L tokenizer\n",
    "# - 띄어쓰기 단위로 나눈 어절 토큰 : L토큰 + R토큰\n",
    "# (예 : '공원에' -> '공원' + '에',  '공부하는' -> '공부' + '하는')\n",
    "# 분리 기준 : 점수가 가장 높은 L토큰을 찾아내는 원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()} # 응집확률이 높게 되도록 뽑아낸다 \n",
    "l_tokenizer = LTokenizer(scores=scores) # 그냥 쪼개지 말고, LTokenizer로 쪼개자! \n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최대 점수 토크나이저\n",
    "# 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀸스를 순차적으로 찾아내는 토크나이저\n",
    "# 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0.07856876882976202,\n",
       " 0.09217735975351507,\n",
       " 0.20075093164820865,\n",
       " 0.17387399904982392)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table['국'].cohesion_forward ,word_score_table['국제'].cohesion_forward ,word_score_table['국제사'].cohesion_forward ,word_score_table['국제사회'].cohesion_forward ,word_score_table['국제사회와'].cohesion_forward # \"와\"가 생기자마자 확률이 떨어지므로, 여기서 끊어주는 것이다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아ㅋ영화존잼쓰 ㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋㅋ영화존잼쓰 ㅠㅠㅠㄴㄴㄴ😊😊😊😊😊😊😊😊😊\n"
     ]
    }
   ],
   "source": [
    "# SOYNLP를 이용한 반복되는 문자 정제\n",
    "# ㅋㅋ, ㅎㅎ 등의 이모티콘인 경우 불필요하게 연속되는 경우 많음\n",
    "# ㅋㅋ, ㅋㅋㅋ, ㅋㅋㅋㅋ와 같은 경우를 모두 서로 다른 단어로 처리하는 것은 불필요\n",
    "# >> 반복되는 것은 하나로 정규화 \n",
    "\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋ이영화존잼쓰 ㅠㅠㅠㅠ\", num_repeats=1))\n",
    "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
    "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰 ㅠㅠㅠㅠㅠㅠㅠㄴㄴㄴㄴㄴㄴ😊😊😊😊😊😊😊😊😊\", num_repeats=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize(\"와하하하하핫\", num_repeats=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\NLP\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.add_dictionary(words=\"은경이\", tag=\"Noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맥캡은 코랩에서 사용할 수 있다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자단어 사용자품사\n",
      "추가할단어 추가할품사\n",
      "['사용자', '단어', '를', '추가', '하', 'ㄹ', '수', '있', '습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "# 사용자 정의 사전 추가\n",
    "# 추가할 단어와 그에 해당하는 품사를 리스트로 넣어줍니다.\n",
    "user_dictionary = [('사용자단어', '사용자품사'), ('추가할단어', '추가할품사')]\n",
    "\n",
    "# 사용자 정의 사전 적용\n",
    "for word, pos in user_dictionary:\n",
    "    print(word, pos)\n",
    "    komoran.tagset.setdefault(word, pos)\n",
    "\n",
    "# 예시 문장 형태소 분석\n",
    "result = komoran.morphs(\"사용자단어를 추가할 수 있습니다.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EC': '연결 어미',\n",
       " 'EF': '종결 어미',\n",
       " 'EP': '선어말어미',\n",
       " 'ETM': '관형형 전성 어미',\n",
       " 'ETN': '명사형 전성 어미',\n",
       " 'IC': '감탄사',\n",
       " 'JC': '접속 조사',\n",
       " 'JKB': '부사격 조사',\n",
       " 'JKC': '보격 조사',\n",
       " 'JKG': '관형격 조사',\n",
       " 'JKO': '목적격 조사',\n",
       " 'JKQ': '인용격 조사',\n",
       " 'JKS': '주격 조사',\n",
       " 'JKV': '호격 조사',\n",
       " 'JX': '보조사',\n",
       " 'MAG': '일반 부사',\n",
       " 'MAJ': '접속 부사',\n",
       " 'MM': '관형사',\n",
       " 'NA': '분석불능범주',\n",
       " 'NF': '명사추정범주',\n",
       " 'NNB': '의존 명사',\n",
       " 'NNG': '일반 명사',\n",
       " 'NNP': '고유 명사',\n",
       " 'NP': '대명사',\n",
       " 'NR': '수사',\n",
       " 'NV': '용언추정범주',\n",
       " 'SE': '줄임표',\n",
       " 'SF': '마침표, 물음표, 느낌표',\n",
       " 'SH': '한자',\n",
       " 'SL': '외국어',\n",
       " 'SN': '숫자',\n",
       " 'SO': '붙임표(물결,숨김,빠짐)',\n",
       " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
       " 'SS': '따옴표,괄호표,줄표',\n",
       " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
       " 'VA': '형용사',\n",
       " 'VCN': '부정 지정사',\n",
       " 'VCP': '긍정 지정사',\n",
       " 'VV': '동사',\n",
       " 'VX': '보조 용언',\n",
       " 'XPN': '체언 접두사',\n",
       " 'XR': '어근',\n",
       " 'XSA': '형용사 파생 접미사',\n",
       " 'XSN': '명사파생 접미사',\n",
       " 'XSV': '동사 파생 접미사',\n",
       " '사용자단어': '사용자품사',\n",
       " '추가할단어': '추가할품사'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
