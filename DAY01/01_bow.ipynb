{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 단어 수치화 BOW 방식\n",
    "# - 문장 리스트에서 단어들을 추출 후 빈도순을 번호를 부여 ==> 단어 사전\n",
    "# - 생성된 단어 사전을 기준으로 문장을 수치화 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.vocabulary_\n",
    "# 알파벳 순 인덱스 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 8)\t1 \n",
      " [[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 기반 문장 ==> 수치화 \n",
    "result = vectorizer.transform(raw_documents=corpus)\n",
    "print(result,\"\\n\", result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third',\n",
       "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.toarray())\n",
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc_list=['if you take the blue pill, the story ends' , \n",
    "          'if you take the red pill, you stay in Wonderland', \n",
    "          'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "feature_vect = tfidf_vect.fit_transform( doc_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "## cosine_similarity(X, y)\n",
    "# - X : 비교 기준이 되는 문서의 피처 행렬\n",
    "# - y : 비교하고자 하는 문서의 피처 행렬\n",
    "result = cosine_similarity(feature_vect[0] , feature_vect)\n",
    "print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jamo in c:\\users\\mathn\\appdata\\roaming\\python\\python38\\site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install jamo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
