{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchtext 라이브러리로 텍스트 분류 <hr>\n",
    "- 1단계 - 데이터 전처리 : 숫자형식으로 변환하는 것 까지\n",
    "- 2단계 - 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "# DataPipe 타입 >>> iterator 타입 형변환\n",
    "train_iter = iter(AG_NEWS(split='train'))\n",
    "test_iter = iter(AG_NEWS(split='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label,test_label = [], []\n",
    "for label,txt in train_iter:\n",
    "    train_label.append(label)\n",
    "\n",
    "for label,txt in test_iter:\n",
    "    test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "preprocessed_sentences = []\n",
    "\n",
    "# train_iter는 여기서 예시로 제공된 변수입니다.\n",
    "# 이 코드를 사용하려면 train_iter를 적절히 정의해야 합니다.\n",
    "import string\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "preprocessed_sentences = []\n",
    "\n",
    "train_iter = iter(AG_NEWS(split='train'))\n",
    "\n",
    "# train_iter는 여기서 예시로 제공된 변수입니다.\n",
    "# 이 코드를 사용하려면 train_iter를 적절히 정의해야 합니다.\n",
    "for _, sentence in train_iter:\n",
    "    # 구두점 제거\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 한글과 영문만 남기기\n",
    "    sentence = re.sub(r'[^a-zA-Z가-힣]', ' ', sentence)  # 다른 문자들을 공백으로 대체\n",
    "\n",
    "    sentence = re.sub(r'\\b\\w{1,2}\\b', '', sentence)\n",
    "\n",
    "    # 토큰화된 결과를 리스트에 추가\n",
    "    preprocessed_sentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 토큰화 인스턴스 생성\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = [tokenizer.morphs(str(txt), stem=True) for txt in preprocessed_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = [tokenizer.morphs(str(txt), stem=True) for label,txt in test_iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_tokens]     120000개\n",
      "[test_tokens]      7600개\n",
      "[train_tokens[0]]  18개\n",
      "[test_tokens[0]]   28개\n"
     ]
    }
   ],
   "source": [
    "print(f'[train_tokens]     {len(train_tokens)}개')\n",
    "print(f'[test_tokens]      {len(test_tokens)}개')\n",
    "print(f'[train_tokens[0]]  {len(train_tokens[0])}개')\n",
    "print(f'[test_tokens[0]]   {len(test_tokens[0])}개') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n"
     ]
    }
   ],
   "source": [
    "# 영어 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print('불용어 개수 :', len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for word in train_tokens: \n",
    "    if word not in stop_words: \n",
    "        result.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 생성 함수\n",
    "# 단어사전 생성하기\n",
    "def build_vocab(corpus, vocab_size, special_tokens):\n",
    "    counter = Counter() # 단어 세는 애\n",
    "\n",
    "    # 단어 / 토큰에 대한 빈도 수 계산\n",
    "    for tokens in corpus:\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # 단어 / 어휘 사전 생성하기\n",
    "    vocab = special_tokens\n",
    "\n",
    "    # 빈도수가 높은 단어부터 단어사전에 추가하기. \n",
    "    for token, count in counter.most_common(vocab_size):\n",
    "        vocab.append(token)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(result, vocab_size=5000, special_tokens=['<PAD>', '<UNK>']) # 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<UNK>',\n",
       " 'the',\n",
       " 'and',\n",
       " 'for',\n",
       " 'that',\n",
       " 'The',\n",
       " 'with',\n",
       " 'its',\n",
       " 'said',\n",
       " 'has',\n",
       " 'Reuters',\n",
       " 'from',\n",
       " 'his',\n",
       " 'will',\n",
       " 'was',\n",
       " 'after',\n",
       " 'have',\n",
       " 'new',\n",
       " 'their',\n",
       " 'over',\n",
       " 'are',\n",
       " 'first',\n",
       " 'more',\n",
       " 'but',\n",
       " 'two',\n",
       " 'Monday',\n",
       " 'Wednesday',\n",
       " 'Tuesday',\n",
       " 'Thursday',\n",
       " 'this',\n",
       " 'New',\n",
       " 'Friday',\n",
       " 'company',\n",
       " 'Inc',\n",
       " 'out',\n",
       " 'against',\n",
       " 'into',\n",
       " 'year',\n",
       " 'not',\n",
       " 'than',\n",
       " 'about',\n",
       " 'yesterday',\n",
       " 'last',\n",
       " 'Iraq',\n",
       " 'who',\n",
       " 'were',\n",
       " 'one',\n",
       " 'Microsoft',\n",
       " 'been',\n",
       " 'they',\n",
       " 'million',\n",
       " 'had',\n",
       " 'United',\n",
       " 'Corp',\n",
       " 'years',\n",
       " 'week',\n",
       " 'Sunday',\n",
       " 'would',\n",
       " 'which',\n",
       " 'AFP',\n",
       " 'could',\n",
       " 'oil',\n",
       " 'quot',\n",
       " 'people',\n",
       " 'today',\n",
       " 'prices',\n",
       " 'government',\n",
       " 'percent',\n",
       " 'President',\n",
       " 'says',\n",
       " 'when',\n",
       " 'three',\n",
       " 'time',\n",
       " 'NEW',\n",
       " 'Saturday',\n",
       " 'world',\n",
       " 'next',\n",
       " 'game',\n",
       " 'night',\n",
       " 'off',\n",
       " 'YORK',\n",
       " 'software',\n",
       " 'win',\n",
       " 'back',\n",
       " 'season',\n",
       " 'China',\n",
       " 'World',\n",
       " 'team',\n",
       " 'may',\n",
       " 'second',\n",
       " 'Internet',\n",
       " 'announced',\n",
       " 'Bush',\n",
       " 'billion',\n",
       " 'market',\n",
       " 'security',\n",
       " 'can',\n",
       " 'some',\n",
       " 'all',\n",
       " 'victory',\n",
       " 'killed',\n",
       " 'day',\n",
       " 'most',\n",
       " 'officials',\n",
       " 'deal',\n",
       " 'European',\n",
       " 'other',\n",
       " 'sales',\n",
       " 'down',\n",
       " 'top',\n",
       " 'Cup',\n",
       " 'American',\n",
       " 'record',\n",
       " 'Oil',\n",
       " 'plans',\n",
       " 'group',\n",
       " 'end',\n",
       " 'before',\n",
       " 'business',\n",
       " 'States',\n",
       " 'British',\n",
       " 'reported',\n",
       " 'Minister',\n",
       " 'set',\n",
       " 'ltbgtltbgt',\n",
       " 'lead',\n",
       " 'home',\n",
       " 'four',\n",
       " 'third',\n",
       " 'Iraqi',\n",
       " 'former',\n",
       " 'just',\n",
       " 'York',\n",
       " 'Google',\n",
       " 'month',\n",
       " 'IBM',\n",
       " 'made',\n",
       " 'least',\n",
       " 'technology',\n",
       " 'India',\n",
       " 'report',\n",
       " 'take',\n",
       " 'between',\n",
       " 'make',\n",
       " 'during',\n",
       " 'largest',\n",
       " 'Red',\n",
       " 'maker',\n",
       " 'you',\n",
       " 'Japan',\n",
       " 'companies',\n",
       " 'talks',\n",
       " 'according',\n",
       " 'country',\n",
       " 'them',\n",
       " 'chief',\n",
       " 'won',\n",
       " 'final',\n",
       " 'help',\n",
       " 'another',\n",
       " 'service',\n",
       " 'what',\n",
       " 'expected',\n",
       " 'League',\n",
       " 'leader',\n",
       " 'major',\n",
       " 'her',\n",
       " 'hit',\n",
       " 'say',\n",
       " 'now',\n",
       " 'With',\n",
       " 'profit',\n",
       " 'South',\n",
       " 'through',\n",
       " 'giant',\n",
       " 'way',\n",
       " 'ltA',\n",
       " 'bid',\n",
       " 'get',\n",
       " 'coach',\n",
       " 'since',\n",
       " 'quarter',\n",
       " 'Web',\n",
       " 'After',\n",
       " 'plan',\n",
       " 'under',\n",
       " 'while',\n",
       " 'being',\n",
       " 'still',\n",
       " 'news',\n",
       " 'International',\n",
       " 'him',\n",
       " 'John',\n",
       " 'police',\n",
       " 'Prime',\n",
       " 'Group',\n",
       " 'months',\n",
       " 'early',\n",
       " 'Palestinian',\n",
       " 'agreed',\n",
       " 'five',\n",
       " 'search',\n",
       " 'Australia',\n",
       " 'Sox',\n",
       " 'left',\n",
       " 'music',\n",
       " 'days',\n",
       " 'military',\n",
       " 'industry',\n",
       " 'court',\n",
       " 'only',\n",
       " 'because',\n",
       " 'growth',\n",
       " 'system',\n",
       " 'Olympic',\n",
       " 'election',\n",
       " 'Open',\n",
       " 'Israeli',\n",
       " 'move',\n",
       " 'Apple',\n",
       " 'online',\n",
       " 'state',\n",
       " 'Intel',\n",
       " 'State',\n",
       " 'Windows',\n",
       " 'computer',\n",
       " 'nuclear',\n",
       " 'England',\n",
       " 'weeks',\n",
       " 'official',\n",
       " 'including',\n",
       " 'North',\n",
       " 'services',\n",
       " 'phone',\n",
       " 'mobile',\n",
       " 'Bank',\n",
       " 'National',\n",
       " 'players',\n",
       " 'start',\n",
       " 'Oracle',\n",
       " 'WASHINGTON',\n",
       " 'president',\n",
       " 'high',\n",
       " 'ago',\n",
       " 'latest',\n",
       " 'cut',\n",
       " 'earnings',\n",
       " 'points',\n",
       " 'like',\n",
       " 'Canadian',\n",
       " 'released',\n",
       " 'Russia',\n",
       " 'many',\n",
       " 'rose',\n",
       " 'biggest',\n",
       " 'Russian',\n",
       " 'Washington',\n",
       " 'Iran',\n",
       " 'games',\n",
       " 'Gaza',\n",
       " 'Stocks',\n",
       " 'space',\n",
       " 'shares',\n",
       " 'loss',\n",
       " 'higher',\n",
       " 'attack',\n",
       " 'war',\n",
       " 'Sports',\n",
       " 'there',\n",
       " 'Baghdad',\n",
       " 'troops',\n",
       " 'stocks',\n",
       " 'found',\n",
       " 'data',\n",
       " 'part',\n",
       " 'buy',\n",
       " 'users',\n",
       " 'even',\n",
       " 'For',\n",
       " 'Network',\n",
       " 'city',\n",
       " 'firm',\n",
       " 'held',\n",
       " 'But',\n",
       " 'Europe',\n",
       " 'Pakistan',\n",
       " 'again',\n",
       " 'PeopleSoft',\n",
       " 'release',\n",
       " 'past',\n",
       " 'Boston',\n",
       " 'play',\n",
       " 'West',\n",
       " 'LONDON',\n",
       " 'run',\n",
       " 'Security',\n",
       " 'ahead',\n",
       " 'much',\n",
       " 'international',\n",
       " 'Update',\n",
       " 'reports',\n",
       " 'head',\n",
       " 'forces',\n",
       " 'should',\n",
       " 'trade',\n",
       " 'executive',\n",
       " 'where',\n",
       " 'Two',\n",
       " 'stock',\n",
       " 'economy',\n",
       " 'pay',\n",
       " 'San',\n",
       " 'Research',\n",
       " 'Australian',\n",
       " 'French',\n",
       " 'big',\n",
       " 'use',\n",
       " 'key',\n",
       " 'presidential',\n",
       " 'Linux',\n",
       " 'price',\n",
       " 'economic',\n",
       " 'work',\n",
       " 'offer',\n",
       " 'federal',\n",
       " 'open',\n",
       " 'six',\n",
       " 'gold',\n",
       " 'man',\n",
       " 'fell',\n",
       " 'beat',\n",
       " 'took',\n",
       " 'America',\n",
       " 'round',\n",
       " 'near',\n",
       " 'public',\n",
       " 'jobs',\n",
       " 'share',\n",
       " 'title',\n",
       " 'dollar',\n",
       " 'number',\n",
       " 'nearly',\n",
       " 'called',\n",
       " 'Street',\n",
       " 'strong',\n",
       " 'investors',\n",
       " 'Darfur',\n",
       " 'series',\n",
       " 'Wall',\n",
       " 'used',\n",
       " 'One',\n",
       " 'put',\n",
       " 'Israel',\n",
       " 'how',\n",
       " 'your',\n",
       " 'around',\n",
       " 'Press',\n",
       " 'any',\n",
       " 'support',\n",
       " 'attacks',\n",
       " 'contract',\n",
       " 'Florida',\n",
       " 'NASA',\n",
       " 'Union',\n",
       " 'Japanese',\n",
       " 'Court',\n",
       " 'Quote',\n",
       " 'City',\n",
       " 'car',\n",
       " 'killing',\n",
       " 'close',\n",
       " 'Yankees',\n",
       " 'Kerry',\n",
       " 'October',\n",
       " 'workers',\n",
       " 'Sun',\n",
       " 'Says',\n",
       " 'September',\n",
       " 'Game',\n",
       " 'More',\n",
       " 'News',\n",
       " 'free',\n",
       " 'peace',\n",
       " 'Federal',\n",
       " 'global',\n",
       " 'despite',\n",
       " 'leaders',\n",
       " 'case',\n",
       " 'version',\n",
       " 'leading',\n",
       " 'rival',\n",
       " 'France',\n",
       " 'following',\n",
       " 'per',\n",
       " 'agreement',\n",
       " 'late',\n",
       " 'also',\n",
       " 'face',\n",
       " 'might',\n",
       " 'Arafat',\n",
       " 'right',\n",
       " 'rise',\n",
       " 'launch',\n",
       " 'Korea',\n",
       " 'power',\n",
       " 'products',\n",
       " 'amp',\n",
       " 'drug',\n",
       " 'program',\n",
       " 'region',\n",
       " 'fourth',\n",
       " 'long',\n",
       " 'return',\n",
       " 'both',\n",
       " 'test',\n",
       " 'video',\n",
       " 'customers',\n",
       " 'Sony',\n",
       " 'bomb',\n",
       " 'away',\n",
       " 'half',\n",
       " 'worlds',\n",
       " 'demand',\n",
       " 'future',\n",
       " 'race',\n",
       " 'keep',\n",
       " 'recent',\n",
       " 'job',\n",
       " 'decision',\n",
       " 'campaign',\n",
       " 'November',\n",
       " 'research',\n",
       " 'charges',\n",
       " 'give',\n",
       " 'such',\n",
       " 'meeting',\n",
       " 'due',\n",
       " 'good',\n",
       " 'wireless',\n",
       " 'here',\n",
       " 'player',\n",
       " 'scored',\n",
       " 'Michael',\n",
       " 'football',\n",
       " 'minister',\n",
       " 'told',\n",
       " 'death',\n",
       " 'Profit',\n",
       " 'seven',\n",
       " 'California',\n",
       " 'May',\n",
       " 'Profile',\n",
       " 'champion',\n",
       " 'Commission',\n",
       " 'CEO',\n",
       " 'capital',\n",
       " 'results',\n",
       " 'Shares',\n",
       " 'political',\n",
       " 'without',\n",
       " 'several',\n",
       " 'whether',\n",
       " 'financial',\n",
       " 'manager',\n",
       " 'Air',\n",
       " 'This',\n",
       " 'costs',\n",
       " 'saying',\n",
       " 'Canada',\n",
       " 'Computer',\n",
       " 'elections',\n",
       " 'trial',\n",
       " 'Series',\n",
       " 'best',\n",
       " 'Hurricane',\n",
       " 'site',\n",
       " 'lower',\n",
       " 'men',\n",
       " 'become',\n",
       " 'General',\n",
       " 'digital',\n",
       " 'Chinese',\n",
       " 'Britain',\n",
       " 'network',\n",
       " 'line',\n",
       " 'Texas',\n",
       " 'show',\n",
       " 'launched',\n",
       " 'life',\n",
       " 'national',\n",
       " 'straight',\n",
       " 'nation',\n",
       " 'Wireless',\n",
       " 'thirdquarter',\n",
       " 'making',\n",
       " 'battle',\n",
       " 'media',\n",
       " 'across',\n",
       " 'Sudan',\n",
       " 'yearold',\n",
       " 'lost',\n",
       " 'Oct',\n",
       " 'own',\n",
       " 'increase',\n",
       " 'dead',\n",
       " 'place',\n",
       " 'little',\n",
       " 'winning',\n",
       " 'weekend',\n",
       " 'interest',\n",
       " 'email',\n",
       " 'running',\n",
       " 'Williams',\n",
       " 'strike',\n",
       " 'agency',\n",
       " 'Over',\n",
       " 'quarterly',\n",
       " 'well',\n",
       " 'history',\n",
       " 'sell',\n",
       " 'using',\n",
       " 'fall',\n",
       " 'likely',\n",
       " 'taking',\n",
       " 'SAN',\n",
       " 'foreign',\n",
       " 'hopes',\n",
       " 'German',\n",
       " 'Its',\n",
       " 'Germany',\n",
       " 'vote',\n",
       " 'fans',\n",
       " 'she',\n",
       " 'fight',\n",
       " 'management',\n",
       " 'warned',\n",
       " 'Nov',\n",
       " 'House',\n",
       " 'bank',\n",
       " 'consumer',\n",
       " 'August',\n",
       " 'come',\n",
       " 'Yahoo',\n",
       " 'accused',\n",
       " 'Department',\n",
       " 'showed',\n",
       " 'Search',\n",
       " 'Indian',\n",
       " 'morning',\n",
       " 'did',\n",
       " 'among',\n",
       " 'rates',\n",
       " 'shot',\n",
       " 'led',\n",
       " 'match',\n",
       " 'Afghan',\n",
       " 'operating',\n",
       " 'Space',\n",
       " 'Nations',\n",
       " 'posted',\n",
       " 'Former',\n",
       " 'chip',\n",
       " 'hostage',\n",
       " 'better',\n",
       " 'few',\n",
       " 'takes',\n",
       " 'iPod',\n",
       " 'militants',\n",
       " 'behind',\n",
       " 'action',\n",
       " 'University',\n",
       " 'possible',\n",
       " 'school',\n",
       " 'Afghanistan',\n",
       " 'Athens',\n",
       " 'going',\n",
       " 'too',\n",
       " 'claims',\n",
       " 'When',\n",
       " 'wins',\n",
       " 'board',\n",
       " 'amid',\n",
       " 'Report',\n",
       " 'trading',\n",
       " 'rate',\n",
       " 'NFL',\n",
       " 'small',\n",
       " 'David',\n",
       " 'Online',\n",
       " 'began',\n",
       " 'injured',\n",
       " 'takeover',\n",
       " 'information',\n",
       " 'control',\n",
       " 'Championship',\n",
       " 'Giants',\n",
       " 'Americans',\n",
       " 'almost',\n",
       " 'same',\n",
       " 'phones',\n",
       " 'Big',\n",
       " 'eight',\n",
       " 'Olympics',\n",
       " 'violence',\n",
       " 'came',\n",
       " 'scientists',\n",
       " 'signed',\n",
       " 'London',\n",
       " 'crude',\n",
       " 'Champions',\n",
       " 'got',\n",
       " 'helped',\n",
       " 'Sept',\n",
       " 'bankruptcy',\n",
       " 'teams',\n",
       " 'profits',\n",
       " 'see',\n",
       " 'tax',\n",
       " 'change',\n",
       " 'look',\n",
       " 'senior',\n",
       " 'soldiers',\n",
       " 'Ltd',\n",
       " 'offering',\n",
       " 'nations',\n",
       " 'those',\n",
       " 'step',\n",
       " 'boost',\n",
       " 'reach',\n",
       " 'medal',\n",
       " 'died',\n",
       " 'women',\n",
       " 'television',\n",
       " 'ended',\n",
       " 'African',\n",
       " 'Test',\n",
       " 'Blair',\n",
       " 'hold',\n",
       " 'Games',\n",
       " 'Sales',\n",
       " 'Africa',\n",
       " 'Houston',\n",
       " 'Spain',\n",
       " 'Chicago',\n",
       " 'barrel',\n",
       " 'meet',\n",
       " 'East',\n",
       " 'source',\n",
       " 'earlier',\n",
       " 'unit',\n",
       " 'less',\n",
       " 'study',\n",
       " 'judge',\n",
       " 'Deal',\n",
       " 'Airways',\n",
       " 'Not',\n",
       " 'access',\n",
       " 'production',\n",
       " 'cuts',\n",
       " 'field',\n",
       " 'northern',\n",
       " 'revenue',\n",
       " 'markets',\n",
       " 'energy',\n",
       " 'gets',\n",
       " 'ATHENS',\n",
       " 'yet',\n",
       " 'cash',\n",
       " 'party',\n",
       " 'First',\n",
       " 'Service',\n",
       " 'efforts',\n",
       " 'begin',\n",
       " 'southern',\n",
       " 'NBA',\n",
       " 'already',\n",
       " 'soon',\n",
       " 'concerns',\n",
       " 'calls',\n",
       " 'Grand',\n",
       " 'opening',\n",
       " 'gave',\n",
       " 'must',\n",
       " 'countries',\n",
       " 'members',\n",
       " 'conference',\n",
       " 'defense',\n",
       " 'hours',\n",
       " 'star',\n",
       " 'trying',\n",
       " 'money',\n",
       " 'Association',\n",
       " 'Business',\n",
       " 'enough',\n",
       " 'yards',\n",
       " 'Out',\n",
       " 'ever',\n",
       " 'corporate',\n",
       " 'call',\n",
       " 'Communications',\n",
       " 'Italian',\n",
       " 'Systems',\n",
       " 'visit',\n",
       " 'force',\n",
       " 'outside',\n",
       " 'Chief',\n",
       " 'law',\n",
       " 'George',\n",
       " 'sale',\n",
       " 'growing',\n",
       " 'health',\n",
       " 'within',\n",
       " 'others',\n",
       " 'Software',\n",
       " 'Paul',\n",
       " 'low',\n",
       " 'computers',\n",
       " 'Airlines',\n",
       " 'reached',\n",
       " 'continue',\n",
       " 'TOKYO',\n",
       " 'Reserve',\n",
       " 'need',\n",
       " 'Bill',\n",
       " 'Arsenal',\n",
       " 'until',\n",
       " 'makes',\n",
       " 'aimed',\n",
       " 'Council',\n",
       " 'arrested',\n",
       " 'stake',\n",
       " 'Three',\n",
       " 'stop',\n",
       " 'performance',\n",
       " 'fire',\n",
       " 'cost',\n",
       " 'From',\n",
       " 'taken',\n",
       " 'charged',\n",
       " 'ready',\n",
       " 'gas',\n",
       " 'rebels',\n",
       " 'drop',\n",
       " 'competition',\n",
       " 'find',\n",
       " 'FRANCISCO',\n",
       " 'forecast',\n",
       " 'fuel',\n",
       " 'analysts',\n",
       " 'Manchester',\n",
       " 'opposition',\n",
       " 'Cisco',\n",
       " 'Yasser',\n",
       " 'legal',\n",
       " 'far',\n",
       " 'effort',\n",
       " 'net',\n",
       " 'continued',\n",
       " 'White',\n",
       " 'starting',\n",
       " 'point',\n",
       " 'failed',\n",
       " 'wants',\n",
       " 'product',\n",
       " 'authorities',\n",
       " 'Sharon',\n",
       " 'airline',\n",
       " 'nine',\n",
       " 'Davis',\n",
       " 'Palestinians',\n",
       " 'systems',\n",
       " 'popular',\n",
       " 'air',\n",
       " 'each',\n",
       " 'aid',\n",
       " 'Secretary',\n",
       " 'list',\n",
       " 'local',\n",
       " 'finally',\n",
       " 'union',\n",
       " 'threat',\n",
       " 'main',\n",
       " 'Dell',\n",
       " 'Dollar',\n",
       " 'central',\n",
       " 'club',\n",
       " 'filed',\n",
       " 'sign',\n",
       " 'thousands',\n",
       " 'general',\n",
       " 'office',\n",
       " 'Ivan',\n",
       " 'They',\n",
       " 'spending',\n",
       " 'Asian',\n",
       " 'executives',\n",
       " 'Army',\n",
       " 'Top',\n",
       " 'weapons',\n",
       " 'toward',\n",
       " 'seen',\n",
       " 'retailer',\n",
       " 'raised',\n",
       " 'further',\n",
       " 'Madrid',\n",
       " 'Prices',\n",
       " 'dollars',\n",
       " 'investment',\n",
       " 'BAGHDAD',\n",
       " 'quarterback',\n",
       " 'Stadium',\n",
       " 'league',\n",
       " 'operations',\n",
       " 'personal',\n",
       " 'designed',\n",
       " 'looking',\n",
       " 'hits',\n",
       " 'Miami',\n",
       " 'pressure',\n",
       " 'heart',\n",
       " 'coming',\n",
       " 'human',\n",
       " 'euro',\n",
       " 'Gold',\n",
       " 'Francisco',\n",
       " 'size',\n",
       " 'Los',\n",
       " 'Jones',\n",
       " 'went',\n",
       " 'THE',\n",
       " 'family',\n",
       " 'rally',\n",
       " 'Bay',\n",
       " 'ruling',\n",
       " 'gains',\n",
       " 'career',\n",
       " 'crisis',\n",
       " 'Trade',\n",
       " 'Real',\n",
       " 'once',\n",
       " 'cell',\n",
       " 'getting',\n",
       " 'High',\n",
       " 'rights',\n",
       " 'Bowl',\n",
       " 'Center',\n",
       " 'chairman',\n",
       " 'insurance',\n",
       " 'Time',\n",
       " 'side',\n",
       " 'drive',\n",
       " 'Tokyo',\n",
       " 'Muslim',\n",
       " 'Nokia',\n",
       " 'allow',\n",
       " 'injury',\n",
       " 'charge',\n",
       " 'powerful',\n",
       " 'Exchange',\n",
       " 'Talks',\n",
       " 'Ryder',\n",
       " 'Calif',\n",
       " 'problems',\n",
       " 'Delta',\n",
       " 'Mark',\n",
       " 'investigation',\n",
       " 'sold',\n",
       " 'annual',\n",
       " 'working',\n",
       " 'provide',\n",
       " 'rivals',\n",
       " 'desktop',\n",
       " 'goal',\n",
       " 'fighting',\n",
       " 'sent',\n",
       " 'fears',\n",
       " 'Astros',\n",
       " 'Tony',\n",
       " 'selling',\n",
       " 'Singh',\n",
       " 'then',\n",
       " 'attempt',\n",
       " 'Coast',\n",
       " 'planned',\n",
       " 'fired',\n",
       " 'center',\n",
       " 'hope',\n",
       " 'children',\n",
       " 'Asia',\n",
       " 'policy',\n",
       " 'Boeing',\n",
       " 'store',\n",
       " 'supply',\n",
       " 'Police',\n",
       " 'name',\n",
       " 'available',\n",
       " 'full',\n",
       " 'times',\n",
       " 'Now',\n",
       " 'never',\n",
       " 'Angeles',\n",
       " 'expectations',\n",
       " 'chance',\n",
       " 'Win',\n",
       " 'Islamic',\n",
       " 'hard',\n",
       " 'businesses',\n",
       " 'rules',\n",
       " 'known',\n",
       " 'Paris',\n",
       " 'ban',\n",
       " 'large',\n",
       " 'holiday',\n",
       " 'consumers',\n",
       " 'prime',\n",
       " 'Yukos',\n",
       " 'firms',\n",
       " 'Tech',\n",
       " 'engine',\n",
       " 'army',\n",
       " 'UPDATE',\n",
       " 'push',\n",
       " 'named',\n",
       " 'missing',\n",
       " 'WalMart',\n",
       " 'stores',\n",
       " 'Johnson',\n",
       " 'Green',\n",
       " 'runs',\n",
       " 'turn',\n",
       " 'development',\n",
       " 'try',\n",
       " 'confirmed',\n",
       " 'retail',\n",
       " 'unveiled',\n",
       " 'approved',\n",
       " 'survey',\n",
       " 'Will',\n",
       " 'AMD',\n",
       " 'private',\n",
       " 'leave',\n",
       " 'asked',\n",
       " 'Music',\n",
       " 'regulators',\n",
       " 'order',\n",
       " 'Congress',\n",
       " 'Wins',\n",
       " 'championship',\n",
       " 'warning',\n",
       " 'groups',\n",
       " 'focus',\n",
       " 'want',\n",
       " 'above',\n",
       " 'flight',\n",
       " 'target',\n",
       " 'Some',\n",
       " 'bring',\n",
       " 'decided',\n",
       " 'There',\n",
       " 'terror',\n",
       " 'Team',\n",
       " 'Dow',\n",
       " 'short',\n",
       " 'current',\n",
       " 'suicide',\n",
       " 'shows',\n",
       " 'Italy',\n",
       " 'rising',\n",
       " 'And',\n",
       " 'defeat',\n",
       " 'Football',\n",
       " 'Seattle',\n",
       " 'Putin',\n",
       " 'cent',\n",
       " 'lawsuit',\n",
       " 'risk',\n",
       " 'fraud',\n",
       " 'December',\n",
       " 'Woods',\n",
       " 'Disney',\n",
       " 'process',\n",
       " 'issue',\n",
       " 'suspected',\n",
       " 'probe',\n",
       " 'Ireland',\n",
       " 'great',\n",
       " 'area',\n",
       " 'Fallujah',\n",
       " 'employees',\n",
       " 'claim',\n",
       " 'baseball',\n",
       " 'rebel',\n",
       " 'That',\n",
       " 'DVD',\n",
       " 'Mike',\n",
       " 'later',\n",
       " 'turned',\n",
       " 'worth',\n",
       " 'Mobile',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 : 문자 > 숫자 변환\n",
    "token2id = {token: idx for idx, token in enumerate(vocab)}\n",
    "\n",
    "# 인코딩 : 숫자 > 문자 변환\n",
    "id2token = {idx: token for idx, token in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰에 문자를 정수로 변환 및 단어/어휘 사전에 없는 문자도 처리\n",
    "UNK_ID =token2id.get('<UNK>') \n",
    "\n",
    "trainID = [[token2id.get(token, UNK_ID) for token in text] for text in train_tokens]\n",
    "testID = [[token2id.get(token, UNK_ID) for token in text] for text in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_length, pad, start = 'R'):\n",
    "    result = []\n",
    "    for sen in sentences:\n",
    "        sen = sen[:max_length] if start == 'R' else sen[:-max_length] #start 매개변수가 R이면 오른쪽에서 잘라내기\n",
    "        padd_sen = list(sen) + [pad]*(max_length - len(sen)) if start =='R' else ([pad]*(max_length - len(sen)) + list(sen)) # start 매개변수가 R이면 오른쪽부터 패딩 넣기\n",
    "        result.append(padd_sen)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 테스트용 데이터 패딩 처리\n",
    "PAD_ID = token2id.get('<PAD>')\n",
    "MAX_LENGTH = 32  # 학습할 때 총 32개의 히든 스테이트를 갖게 됨\n",
    "\n",
    "# 32개의 단어들만 존재\n",
    "train_ids = pad_sequences(trainID, MAX_LENGTH, PAD_ID)\n",
    "test_ids = pad_sequences(testID, MAX_LENGTH, PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_ids] ---> 32개\n",
      "[test_ids] ---> 32개\n"
     ]
    }
   ],
   "source": [
    "print(f'[train_ids] ---> {len(train_ids[0])}개')\n",
    "print(f'[test_ids] ---> {len(test_ids[0])}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.Series(train_label)\n",
    "train_label = train.replace({1:0,2:1,3:2,4:3})\n",
    "train_label = train_label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    30000\n",
       "3    30000\n",
       "1    30000\n",
       "0    30000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series(test_label)\n",
    "test_label = test.replace({1:0,2:1,3:2,4:3})\n",
    "test_label = test_label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1900\n",
       "3    1900\n",
       "1    1900\n",
       "0    1900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 32]) torch.Size([120000])\n"
     ]
    }
   ],
   "source": [
    "## 데이터셋 생성 : list -> tensor\n",
    "# 학습용 데이터셋\n",
    "dataTS = torch.LongTensor(train_ids)\n",
    "labelTS = torch.tensor(train_label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(dataTS.shape, labelTS.shape)\n",
    "trainDS = TensorDataset(dataTS, labelTS)\n",
    "\n",
    "\n",
    "# 테스트용 데이터셋\n",
    "testdataTS = torch.LongTensor(test_ids)\n",
    "testlabelTS = torch.tensor(test_label, dtype=torch.float32)\n",
    "testDS = TensorDataset(testdataTS, testlabelTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trainDL = DataLoader(trainDS, batch_size = BATCH_SIZE, shuffle = True)\n",
    "testDL = DataLoader(testDS, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_vocab,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            n_layers,\n",
    "            dropout=0.5,\n",
    "            bidirectional=True,\n",
    "            model_type='lstm'\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        if model_type == 'rnn':\n",
    "            self.model = nn.RNN(\n",
    "                input_size=embedding_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=n_layers,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,  # batch_first = True → (batch, seq, feature)\n",
    "            )\n",
    "        elif model_type =='lstm':\n",
    "            self.model = nn.LSTM(\n",
    "                input_size = embedding_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=n_layers,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim*2, 1)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim,1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        output, _ = self.model(embeddings)\n",
    "        last_output = output[:,-1,:]\n",
    "        last_output = self.dropout(last_output)\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 관련 변수\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "MODEL = SentenceClassifier(len(token2id),64,128,2)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 5\n",
    "LOSS_FN = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = torch.optim.Adam(MODEL.parameters(), lr=0.001)\n",
    "SCHEDULER = ReduceLROnPlateau(OPTIMIZER, mode = 'min', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, DL, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    lossList = []\n",
    "    for i, (ids, label) in enumerate(DL): \n",
    "        label = label.to(DEVICE).unsqueeze(1)\n",
    "        ids = ids.to(DEVICE)\n",
    "\n",
    "        output = model(ids)\n",
    "        \n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lossList.append(loss.item())\n",
    "        \n",
    "    train_loss = np.mean(lossList)\n",
    "    print(f'[Train loss] ==> {train_loss:.4f}')\n",
    "    return train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, DL, loss_fn):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct = []\n",
    "    with torch.no_grad():\n",
    "        for ids, label in DL:\n",
    "            label = label.to(DEVICE).unsqueeze(1)\n",
    "            ids = ids.to(DEVICE)\n",
    "\n",
    "            output = model(ids)\n",
    "            loss = loss_fn(output, label) \n",
    "            losses.append(loss.item())\n",
    "            yhat = torch.sigmoid(output) > 0.5\n",
    "            correct.extend(\n",
    "                torch.eq(yhat, label).cpu().tolist()\n",
    "            )\n",
    "        \n",
    "    val_loss = np.mean(losses)\n",
    "    val_acc = np.mean(correct) \n",
    "    print(f'[Valid loss] ==> {val_loss}    [Valid Accuracy] ==> {val_acc}')\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train loss] ==> 0.0000\n",
      "[Valid loss] ==> 0.0    [Valid Accuracy] ==> 0.2505263157894737\n",
      "Epoch 1/5, Train Loss : 0.0000, Val Loss : 0.0000, Val Acc : 0.2505\n",
      "[Train loss] ==> 0.0000\n",
      "[Valid loss] ==> 0.0    [Valid Accuracy] ==> 0.2505263157894737\n",
      "Epoch 2/5, Train Loss : 0.0000, Val Loss : 0.0000, Val Acc : 0.2505\n",
      "[Train loss] ==> 0.0000\n",
      "[Valid loss] ==> 0.0    [Valid Accuracy] ==> 0.2505263157894737\n",
      "Epoch 3/5, Train Loss : 0.0000, Val Loss : 0.0000, Val Acc : 0.2505\n",
      "[Train loss] ==> 0.0000\n",
      "[Valid loss] ==> 0.0    [Valid Accuracy] ==> 0.2505263157894737\n",
      "Epoch 4/5, Train Loss : 0.0000, Val Loss : 0.0000, Val Acc : 0.2505\n",
      "조기 종료 at epoch 3\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = training(MODEL, trainDL, LOSS_FN, OPTIMIZER)\n",
    "    val_loss, val_acc = testing(MODEL, testDL, LOSS_FN)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(val_loss) \n",
    "    test_acc.append(val_acc)\n",
    "\n",
    "    SCHEDULER.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss : {train_loss:.4f}, Val Loss : {val_loss:.4f}, Val Acc : {val_acc:.4f}\")\n",
    "\n",
    "    if SCHEDULER.num_bad_epochs >= SCHEDULER.patience:\n",
    "        print(f'조기 종료 at epoch {epoch}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.0000  Test Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "train_loss_avg = np.mean(train_losses)\n",
    "test_loss_avg = np.mean(test_losses)\n",
    "print(f\"Train Loss : {train_loss_avg:.4f}  Test Loss: {test_loss_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
